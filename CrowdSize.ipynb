{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMJP6Qt51qzPUWIErQ1Pi2m",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PrasadSingh/coursera-test/blob/master/CrowdSize.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "7UOhUJwENa-T"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the weights and cfg files using the following commands\n",
        "!wget https://pjreddie.com/media/files/yolov3.weights\n",
        "!wget https://raw.githubusercontent.com/pjreddie/darknet/master/cfg/yolov3.cfg\n",
        "\n",
        "\n",
        "net = cv2.dnn.readNet(\"yolov3.weights\", \"yolov3.cfg\")\n",
        "layer_names = net.getLayerNames()\n",
        "#The line below has been changed to accomodate the changes in the OpenCV library.\n",
        "output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rtl3RRvDNvn9",
        "outputId": "f99a491a-b036-4271-a6b5-fbd792a602f9"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-09-20 02:50:41--  https://pjreddie.com/media/files/yolov3.weights\n",
            "Resolving pjreddie.com (pjreddie.com)... 162.0.215.52\n",
            "Connecting to pjreddie.com (pjreddie.com)|162.0.215.52|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 248007048 (237M) [application/octet-stream]\n",
            "Saving to: ‘yolov3.weights.2’\n",
            "\n",
            "yolov3.weights.2    100%[===================>] 236.52M  30.6MB/s    in 9.1s    \n",
            "\n",
            "2024-09-20 02:50:50 (26.0 MB/s) - ‘yolov3.weights.2’ saved [248007048/248007048]\n",
            "\n",
            "--2024-09-20 02:50:50--  https://raw.githubusercontent.com/pjreddie/darknet/master/cfg/yolov3.cfg\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8342 (8.1K) [text/plain]\n",
            "Saving to: ‘yolov3.cfg.2’\n",
            "\n",
            "yolov3.cfg.2        100%[===================>]   8.15K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-09-20 02:50:50 (79.9 MB/s) - ‘yolov3.cfg.2’ saved [8342/8342]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "video_path = 'https://www.youtube.com/watch?v=y2zyucfCyjM'\n",
        "cap = cv2.VideoCapture(video_path)"
      ],
      "metadata": {
        "id": "36lFLxmwQ3bR"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define time frame\n",
        "start_frame = 14 * 30 # Assuming 30 FPS\n",
        "end_frame = 32 * 30"
      ],
      "metadata": {
        "id": "bAaryY7ARTxG"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the current frame position to start frame\n",
        "cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9BvTvBXRlBd",
        "outputId": "163332e6-9f37-4268-e319-34a397391c5a"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "frame_count = start_frame\n",
        "people_count = 0"
      ],
      "metadata": {
        "id": "9k_jNa_5R3FL"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "people_count = 0\n",
        "boxes = []\n",
        "confidences = []\n",
        "class_ids = []\n",
        "end_frame = 30  # Define your end frame based on the video\n",
        "\n",
        "while cap.isOpened() and frame_count <= end_frame:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    height, width, _ = frame.shape\n",
        "    blob = cv2.dnn.blobFromImage(frame, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
        "    net.setInput(blob)\n",
        "\n",
        "    # Forward pass to get output\n",
        "    outs = net.forward(output_layers)\n",
        "\n",
        "    # Process the output\n",
        "    for out in outs:\n",
        "        for detection in out:\n",
        "            scores = detection[5:]\n",
        "            class_id = np.argmax(scores)\n",
        "            confidence = scores[class_id]\n",
        "            if confidence > 0.5 and class_id == 0:  # class_id 0 for 'person'\n",
        "                center_x = int(detection[0] * width)\n",
        "                center_y = int(detection[1] * height)\n",
        "                w = int(detection[2] * width)\n",
        "                h = int(detection[3] * height)\n",
        "                x = int(center_x - w / 2)\n",
        "                y = int(center_y - h / 2)\n",
        "\n",
        "                boxes.append([x, y, w, h])\n",
        "                confidences.append(float(confidence))\n",
        "                class_ids.append(class_id)\n",
        "\n",
        "    # Apply Non-Maxima Suppression\n",
        "    indices = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
        "    for i in indices:\n",
        "        i = i[0]  # NMS returns a list of lists\n",
        "        people_count += 1\n",
        "\n",
        "    frame_count += 1\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "print(f\"Estimated number of people on the bridge: {people_count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDMZOtgcVndf",
        "outputId": "f585b639-8adb-4452-a3dd-8ed303d8b9dd"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estimated number of people on the bridge: 0\n"
          ]
        }
      ]
    }
  ]
}